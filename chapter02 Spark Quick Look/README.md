# Chapter 02 스파크 간단히 살펴보기
- - - 
### 2.1 스파크의 기본 아키텍처
> 한대의 컴퓨터는 대규모 연산을 수행할 만한 자원이나 성능이 부족하다. 
> 컴퓨터 *클러스터* 는 여러 컴퓨터의 자원을 모아 한대의 컴퓨터 처럼 사용하게 해준다.    

* 여기에는 클러스터(즉 컴퓨터 뭉치)에서 작업을 조율해줄 프레임워크가 필요한데 그것이 바로 *스파크* !   
* 스파크가 연산에 사용할 클러스터는 스파크 스탠드얼론, 하둡 YARN, 메소스와 같은 클러스터 매니저에서 관리한다.   
> 사용자는 클러스터 매니저에게 *스파크 애플리케이션* 을 제출하고, 클러스터 매니저는 작업을 클러스터에 적절히 분배
#### 스파크 애플리케이션 = 드라이버프로세스 + 익스큐터 
1. 드라이버 
* 스파크의 심장과 같은 존재, 워커 노드들에 분산된 작업과 데이터를 관리
* 보통 클러스터당 하나씩 존재하지만 여러개가 존재할 수도 있음.
* 사용자 프로그램을 테스크로 변환하여 클러스터로 전송
2. 익스큐터 
* 드라이버 프로세스가 할당한 작업을 수행.   
* 테스크 실행후 결과를 드라이버로 전송
* 어플리케이션에서 사용하는 RDD를 저장하기 위한 메모리 공간 제공

![스파크 아키텍처](https://user-images.githubusercontent.com/60355414/84154186-bf0d5500-aaa1-11ea-94fd-9266877deccc.PNG)

핵심 사항
* 스파크는 사용 가능한 자원을 파악하기 위해 클러스터 매니저를 사용한다.
* 드라이버 프로세스는 주어진 작업을 완료하기 위해 드라이버 프로그램의 명령을 익스큐에사 실행할 책임이있다. 
 - - -
 ### 2.2 스파크의 다양한 언어 API
 > 스파크는 스칼라, 자바, 파이썬, SQL, R등 다양한 언어를 제공한다. 
 *  명령을 보낸다면 sparkContext에서 JVM에서 사용할 수 있는 코드로 변환하여 익스큐터로 전달한다. 
 - - - 
 ### 2.3/4 스파크 API/스파크 시작하기
 > 다양한 언어로 스파크 사용이 가능한 이유는 스파크가 기본적으로 두가지 API를 제공하기 때문이다.
 1. 저수준의 비구조적 API
 2. 고수준의 구조적 API
 > 스파크 애플리케이션 개발하려면, *사용자 명령* 과 *데이터* 를 스파크 애플리케이션에 전송하는 방법을 알아야한다.
 - - -
 ### 2.5 SparkSession
 > 스파크 애플리케이션은 SparkSession(SparkContext)이라 불리는 드라이버 프로세스로 제어한다. 
 >  > SparkSession 인스턴스는 사용자가 정의한 처리 명령을 클러스터에서 실행한다. 
```
 pyspark
```
 - - -
 ### 2.6 DataFrame
 > DataFrame은 가장 대표적인 구조적 API로서, 테이블의 데이터를 로우와 컬럼으로 단순하게 표현.
 > 스키마 : 컬럼과 컬럼의 타입을 정의한 목록
 spark의 DataFrame은 다른 DataFrame들과 구조적으로 동일하지만 여러 컴퓨터에 분산저장 되어 있다는 점에서 차이가 있다.
 #### 파티션
 > 스파크는 모든 익스큐터가 병렬로 처리할 수 있도록 파티션이라는 청크 단위로 데이터를 분할한다.
 > 파티션 : 클러스터의 물리적 머신에 존재하는 로우의 집합.
 * 한번에 처리가능한 파티션의 수 = 클러스터 내에 존재하는 코어의 개수
 * 파티셔닝을 잘해야 테스크가 효율적으로 처리
 - - - 
 ### 2.7 트랜스포메이션
 > 스파크의 핵심 데이터 구조는 *불변성*을 가진다.   
 > 그렇다면 어떻게 사용? DataFrame의 변경을 원한다면 *transformation* 시켜 주어야함.      
```
 myRange = spark.range(1000).toDF("number")
 divisBy2 = myRange.where("number % 2 = 0 ")
```
* 위의 코드를 실행 시켜도 결과가 출력되지 않는다.(응답값이 실행되지만, 결과는 아님) 이는 추상적인 트랜스포메이션만 지정한 상태이기 때문.
 ![ta](https://user-images.githubusercontent.com/60355414/84157104-47412980-aaa5-11ea-99e4-2f91ca65c9ec.PNG)
 1. 좁은 의존성 : 좁은 의존성을 가진 트랜스포메이션은 각 입력 파티션이 하나의 출력 파티션에만 영향을 미친다. 
 2. 넓은 의존성 : 넓은 의존성을 가진 트랜스포메이션은 하나의 입력 파티션이 여러 출력 파티션에 영향을 미친다. 
 3. 파이프라이닝 : 한 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태로 연결된 구조, 연결된 데이터 처리 단계는 한 여러 단계가 서로 동시에, 또는 병렬적으로 수행될 수 있어 효율성의 향상을 꾀할 수 있다. 
 * 좁은 트랜스포메이션을 실행하면 파이프라이닝을 자동적으로 수행한다. 
 #### 지연 연산
 > 스파크는 특정 연산이 내려진 즉시 데이터를 수정하지 않고, 원시 데이터에 적용할 트랜스포메이션을 실행 계획으로 생성한다.   
 * 즉 스파크는 코드를 실행하기 직전까지 버티다가, 실행해야한다면 트랜스포메이션들을 확인하고, 연산에 가장 효율적이도록 트랜스포메이션들을 컴파일한다.
* 전체 데이터 흐름을 최적화하는 엄청난 장점을 가지고 있다.   
* 만약 엄청 많은 트랜스포메이션을 모았는데 결국 row하나만 가져오는 거라면? 스파크에 전부 데이터를 가져와 하나씩 처리하지 않고, 
 데이터소스(데이터가 저장되어 있는 녀석 ex. MySQL, 등)에 생성한 최적 계획을 위임한다. 

 
