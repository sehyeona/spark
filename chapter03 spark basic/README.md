# Chapter03 스파크 기능 둘러보기
- - -
### 3.1 운영용 애플리케이션 실행하기
> spark-submit
```
./bin/spark-submit\
--master local\
./examples/src/main/pi.py 10 
```
spark-submit 명령을 이용하여 대화형 셀에서 개발한 프로그램을 운영용 프로그램으로 쉽게 전환할 수 있다.
- - -
### 3.2 Dataset
> Dataset : 타입 안정성을 지원하는 스파크의 구조적 API
1. 타입 안정성을 지원하기 때문에 초기화에 사용한 데이터 클래스 대신 다른 클래스 사용불가
2. DataFrame의 레코드를 사용자가 정의한 클래스에 할당
3. 할당된 레코드들을 자바, 스칼라의 고정 타입형 컬렉션으로 다루게 해줌   
![용어들](https://user-images.githubusercontent.com/60355414/84241184-1bbc4e80-ab3a-11ea-91df-92f2cc2c7caf.PNG)   
* 필요한 경우에 선택적으로 사용할 수 있다는 장점(DataFrame처럼 뭉치로 있는게 아님)
* 호출되면 row타입의 객체가 아닌 사용자 지정의 객체
* 다수의 소프트 엔지니어가 잘 정의된 인터페이스로 상호작용할때 유용
- - -
### 3.3 구조적 스트리밍
> 스트림 처리용 고수준 API
1. 스트림처리: 신규 데이터를 *끊임없이* 처리해 결과를 만들어 내는 일(=실시간 처리)
* 스트림 처리의 입력 데이터는 무한(입력데이터 : 스트림 처리에 도달한 일련의 이벤트)
* 시작과 끝을 사전에 정의하지 않음
2. batch processing: 데이터를 일정 기간 또는 일정량 정리하여 처리하는 것(=일괄 처리)
* 고정된 입력 데이터 셋을 다룬다
* 스트림 처리와 유사하지만, 결과를 한번만 만들어낸다. 
* 오래된 방식이지만, 컴퓨터의 처리 효율을 높이고, 일정 시점으로 처리하는 업무에는 여전히 유용
#### 스파크의 구조적 스트리밍을 통해, 스트림처리와 배치처리를 혼합하여, 지연시간을 줄이고, 증분처리할 수 있다. 


