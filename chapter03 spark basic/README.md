# Chapter03 스파크 기능 둘러보기
- - -
### 3.1 운영용 애플리케이션 실행하기
> spark-submit
```
./bin/spark-submit\
--master local\
./examples/src/main/pi.py 10 
```
spark-submit 명령을 이용하여 대화형 셀에서 개발한 프로그램을 운영용 프로그램으로 쉽게 전환할 수 있다.
- - -
### 3.2 Dataset
> Dataset : 타입 안정성을 지원하는 스파크의 구조적 API
1. 타입 안정성을 지원하기 때문에 초기화에 사용한 데이터 클래스 대신 다른 클래스 사용불가
2. DataFrame의 레코드를 사용자가 정의한 클래스에 할당
3. 할당된 레코드들을 자바, 스칼라의 고정 타입형 컬렉션으로 다루게 해줌   
![용어들](https://user-images.githubusercontent.com/60355414/84241184-1bbc4e80-ab3a-11ea-91df-92f2cc2c7caf.PNG)   
* 필요한 경우에 선택적으로 사용할 수 있다는 장점(DataFrame처럼 뭉치로 있는게 아님)
* 호출되면 row타입의 객체가 아닌 사용자 지정의 객체
* 다수의 소프트 엔지니어가 잘 정의된 인터페이스로 상호작용할때 유용
- - -
### 3.3 구조적 스트리밍
> 스트림 처리용 고수준 API
1. 스트림처리: 신규 데이터를 *끊임없이* 처리해 결과를 만들어 내는 일(=실시간 처리)
* 스트림 처리의 입력 데이터는 무한(입력데이터 : 스트림 처리에 도달한 일련의 이벤트)
* 시작과 끝을 사전에 정의하지 않음
2. batch processing: 데이터를 일정 기간 또는 일정량 정리하여 처리하는 것(=일괄 처리)
* 고정된 입력 데이터 셋을 다룬다
* 스트림 처리와 유사하지만, 결과를 한번만 만들어낸다. 
* 오래된 방식이지만, 컴퓨터의 처리 효율을 높이고, 일정 시점으로 처리하는 업무에는 여전히 유용
#### 스파크의 구조적 스트리밍을 통해, 스트림처리와 배치처리를 혼합하여, 지연시간을 줄이고, 증분처리할 수 있다. 
- - -
### 3.4 머신러닝과 고급 분석
> 내장된 머신러닝 알고리즘 라이브러리인 MLLIB을 사용해 대규모 머신러닝을 수행할 수 있다. 
1. 대용량 데이터를 대상으로 전처리, 멍잉(원본을 다른형태로 변환 및 매핑), 모델학습 및 예측을 수행가능 
2. 분류, 회귀, 군집화, 딥러닝 등 다양한 예측 모델 사용가능
- - -
### 3.5 저수준 API
> 스파크는 RDD를 통해 자바와 파이썬 객체를 다루는데 필요한 다양한 기본기능(저수준 API)를 제공한다. 
1. 스파크의 거의 모든 기능은 RDD를 통해 만들어졌다. 
2. 고수준 API로 제어하지 못하는 세밀한 부분에서 저수준 API사용가능
3. 단 저수준 API는 고수준 API에서 사용하는 최적화 기법들이 생략되어 언어마다 성능차이가 심하다.
- - -
### 3.7 스파크의 에코시스템
> 스파크의 최고 장점은 커뮤니티가 만들어낸 패키지 에코시스템과 다양한 기능들
* spark-packages.org에서 누구나 패키지를 공개하고 만들어낼 수 있다. 

